{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Made by\n",
        "\n",
        "Lucas Kristiansson\n",
        "980320-5971\n",
        "\n",
        "Rikard Radovac\n",
        "010826-8376\n",
        "\n",
        "Carolina RÃ¶nnewall\n",
        "980322-7900"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py3XRGKkqVO1",
        "outputId": "c5356106-218f-4209-f83a-924241090b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTm7AKxgcOgR"
      },
      "outputs": [],
      "source": [
        "!unzip drive/MyDrive/data/a5_data.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDxlazWSh72R"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def load_vggmodel(device):\n",
        "    weights_id = torchvision.models.VGG16_Weights.IMAGENET1K_V1\n",
        "    vggmodel = torchvision.models.vgg16(weights=weights_id)\n",
        "    vggmodel.eval()\n",
        "    vggtransforms = weights_id.transforms()\n",
        "\n",
        "    # freeze the parameters\n",
        "    for param in vggmodel.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "    vggmodel.to(device)\n",
        "    return vggmodel, vggtransforms\n",
        "\n",
        "def load_resnetmodel(device):\n",
        "    weights_id = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n",
        "    resnetmodel = torchvision.models.resnet50(weights=weights_id)\n",
        "    resnetmodel.eval()\n",
        "    resnettransforms = weights_id.transforms()\n",
        "\n",
        "    # freeze the parameters\n",
        "    for param in resnetmodel.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # in_features = resnetmodel.fc.in_features\n",
        "    # n_classes = 1\n",
        "\n",
        "    # new_outer_layers = nn.Sequential(\n",
        "    #     nn.Linear(in_features=in_features, out_features=n_classes)\n",
        "    #     )\n",
        "\n",
        "    # resnetmodel.fc = new_outer_layers\n",
        "\n",
        "    resnetmodel.to(device)\n",
        "    return resnetmodel, resnettransforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC-6kOH38gPR"
      },
      "outputs": [],
      "source": [
        "# Our CNN baseline\n",
        "class CNNBaseline(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # Assuming 1 class by default\n",
        "        super(CNNBaseline, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces image size to half\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Assuming three pooling layers that halve the image size each time, the image size is reduced to 128/2/2/2 = 16\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Adjusted for 128x128 input images\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Block 2\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Block 3\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Our CNN with batch normalization\n",
        "class CNNBatchNorm(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # Assuming 1 class by default\n",
        "        super(CNNBatchNorm, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces image size to half\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Assuming three pooling layers that halve the image size each time, the image size is reduced to 128/2/2/2 = 16\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Adjusted for 128x128 input images\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        # Block 2\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # Block 3\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Our CNN with layer normalization\n",
        "class CNNLayerNorm(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # Assuming 1 class by default\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        # Use LayerNorm\n",
        "        self.ln1 = nn.LayerNorm([32, 128, 128])  # Adjusted for the output size of this layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces image size to half\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        # Use LayerNorm\n",
        "        self.ln2 = nn.LayerNorm([64, 64, 64])  # Assuming the output size after pooling\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        # Use LayerNorm\n",
        "        self.ln3 = nn.LayerNorm([128, 32, 32])  # Assuming the output size after pooling\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.ln1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.ln2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.ln3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Our CNN with group normalization\n",
        "class CNNGroupNorm(nn.Module):\n",
        "    def __init__(self, num_classes=1, num_groups=8):  # Assuming 1 class by default and 8 groups for GN\n",
        "        super(CNNGroupNorm, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        # Use GroupNorm\n",
        "        self.gn1 = nn.GroupNorm(num_groups=num_groups, num_channels=32)\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        # Use GroupNorm\n",
        "        self.gn2 = nn.GroupNorm(num_groups=num_groups, num_channels=64)\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        # Use GroupNorm\n",
        "        self.gn3 = nn.GroupNorm(num_groups=num_groups, num_channels=128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces image size to half\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Adjusted for 128x128 input images\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.gn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.gn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.gn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Our CNN baseline without pool, will be used to compare with/without residual\n",
        "class CNNWithoutPool(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # Assuming 1 class by default\n",
        "        super(CNNWithoutPool, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=3, kernel_size=3, padding=1)\n",
        "\n",
        "        # Assuming three pooling layers that halve the image size each time, the image size is reduced to 128/2/2/2 = 16\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(3*128*128, 512)  # Adjusted for 128x128 input images\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.conv1(x))\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Our CNN with Residual\n",
        "class CNNResidual(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(CNNResidual, self).__init__()\n",
        "\n",
        "        # Convolutional layer block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolutional layer block 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "\n",
        "        # Convolutional layer block 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=3, kernel_size=3, padding=1)\n",
        "\n",
        "        # Assuming three pooling layers that halve the image size each time, the image size is reduced to 128/2/2/2 = 16\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(3 * 128 * 128, 512)  # Adjusted for 128x128 input images\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        # Block 1\n",
        "        x = F.relu(self.conv1(x))\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        # Block 3\n",
        "        x = self.conv3(x)\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta5js6wEdNg1"
      },
      "outputs": [],
      "source": [
        "folder_path = \"data/a5_data/\"\n",
        "\n",
        "\n",
        "# Without augmentations\n",
        "transform_function = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "folder = ImageFolder(folder_path + \"train\", transform=transform_function)\n",
        "loader = DataLoader(folder, batch_size=16, shuffle=True)\n",
        "\n",
        "folder_test = ImageFolder(folder_path + \"val\", transform=transform_function)\n",
        "loader_test = DataLoader(folder_test, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcSCmcxlrukJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, test_data, device, batch_size, type_set: str = \"val\"):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    for x, y in test_data:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(x).sigmoid()\n",
        "\n",
        "        predicted = torch.round(outputs)\n",
        "\n",
        "\n",
        "        correct += sum(predicted.squeeze() == y)\n",
        "\n",
        "    accuracy = correct / (len(test_data) * batch_size)\n",
        "    print(f\"Accuracy on {type_set}: \", accuracy.item())\n",
        "\n",
        "\n",
        "def train_model(model, dataloader, loader_test, device, epochs: int = 5):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_sum = 0\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "\n",
        "            loss = criterion(output.squeeze(), y.to(torch.float32))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()\n",
        "\n",
        "        batch_size = 16\n",
        "        evaluate_model(model, dataloader, device, batch_size=batch_size, type_set=\"train\")\n",
        "        evaluate_model(model, loader_test, device, batch_size=batch_size)\n",
        "        print(f\"Epoch {epoch + 1} with mean loss: {loss_sum / len(dataloader)}\")\n",
        "        print()\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "models = [CNNBaseline, CNNBatchNorm, CNNLayerNorm, CNNGroupNorm, CNNWithoutPool, CNNResidual]\n",
        "for model_class in models:\n",
        "    model = model_class(num_classes=1)\n",
        "    model.to(device)\n",
        "    print(f\"Training model {model_class}\")\n",
        "    train_model(model, loader, loader_test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7Xc9bxF8H9Z"
      },
      "outputs": [],
      "source": [
        " # # With augmentation\n",
        "transform_function = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.RandomResizedCrop(size=(128, 128), antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "folder = ImageFolder(folder_path + \"train\", transform=transform_function)\n",
        "loader = DataLoader(folder, batch_size=16, shuffle=True)\n",
        "\n",
        "folder_test = ImageFolder(folder_path + \"val\", transform=transform_function)\n",
        "loader_test = DataLoader(folder_test, batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "model = CNNBaseline(num_classes=1)\n",
        "train_model(model, loader, loader_test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf-1DVhrWEHg",
        "outputId": "90b96ed1-a823-479e-e1a3-9c46924f230c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|ââââââââââ| 528M/528M [00:04<00:00, 136MB/s] \n"
          ]
        }
      ],
      "source": [
        "def compute_and_save_features(model, train_folder, eval_folder, transform_function, folder_path, device):\n",
        "\n",
        "    model.eval()\n",
        "    folder = ImageFolder(folder_path + \"train\", transform=transform_function)\n",
        "    loader = DataLoader(train_folder, batch_size=1, shuffle=False)\n",
        "\n",
        "    folder_test = ImageFolder(folder_path + \"val\", transform=transform_function)\n",
        "    loader_test = DataLoader(eval_folder, batch_size=1, shuffle=False)\n",
        "\n",
        "    all_features = []\n",
        "    with torch.no_grad():\n",
        "        for dataloader in [loader, loader_test]:\n",
        "            current_features = []\n",
        "            current_labels = []\n",
        "            for x, y in dataloader:\n",
        "                x = x.to(device)\n",
        "                features = model(x)\n",
        "                current_features.append(features)\n",
        "                current_labels.append(y)\n",
        "            all_features.append((current_features, current_labels))\n",
        "    return all_features[0], all_features[1]\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, transform_function = load_resnetmodel(device)\n",
        "# all layers except classification layer\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "train, test = compute_and_save_features(model, folder, folder_test, transform_function, folder_path, device)\n",
        "torch.save(torch.concat(train[0]), \"resnet.pkl\")\n",
        "torch.save(torch.concat(train[1]), \"resnet_labels.pkl\")\n",
        "\n",
        "torch.save(torch.concat(test[0]), \"resnet_test.pkl\")\n",
        "torch.save(torch.concat(test[1]), \"resnet_labels_test.pkl\")\n",
        "\n",
        "\n",
        "model, transform_function = load_vggmodel(device)\n",
        "# all layers except classification layer\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "train, test = compute_and_save_features(model, folder, folder_test, transform_function, folder_path, device)\n",
        "torch.save(torch.concat(train[0]), \"vggmodel.pkl\")\n",
        "torch.save(torch.concat(train[1]), \"vggmodel_labels.pkl\")\n",
        "\n",
        "torch.save(torch.concat(test[0]), \"vggmodel_test.pkl\")\n",
        "torch.save(torch.concat(test[1]), \"vggmodel_labels_test.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LllGXoicZjH"
      },
      "source": [
        "**Create a classifier head that uses the pre-trained features as inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_pPhyeEclu6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model_input_size(model, model_type: str):\n",
        "\n",
        "    if model_type == \"vgg\":\n",
        "        return model.classifier[0].in_features\n",
        "    elif model_type == \"resnet50\":\n",
        "        return model.fc.in_features\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 1\n",
        "\n",
        "model, transform_function = load_vggmodel(device)\n",
        "in_features = get_model_input_size(model, \"vgg\")\n",
        "vgg_classifier = nn.Sequential(\n",
        "   nn.Linear(in_features, 2048),\n",
        "    nn.BatchNorm1d(num_features=2048),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(2048, n_classes)\n",
        "\n",
        ")\n",
        "\n",
        "model, transform_function = load_resnetmodel(device)\n",
        "\n",
        "in_features = get_model_input_size(model, \"resnet50\")\n",
        "resnet_classifier = nn.Sequential(\n",
        "    nn.Linear(in_features, 2048),\n",
        "    nn.BatchNorm1d(num_features=2048),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(2048, n_classes)\n",
        "\n",
        ")\n",
        "\n",
        "del model\n",
        "del transform_function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOd1Z-t96rFy"
      },
      "source": [
        "Train pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW-PCp-bq1eu"
      },
      "outputs": [],
      "source": [
        "def train_pretrained_model(model, dataloader, loader_test, device, epochs: int = 5):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_sum = 0\n",
        "        for x, y in dataloader:\n",
        "            x = x.view(x.size()[0], -1)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "\n",
        "            loss = criterion(output.squeeze(), y.to(torch.float32))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()\n",
        "\n",
        "        batch_size = 16\n",
        "        evaluate_pretrained_model(model, loader_test, device, batch_size=batch_size)\n",
        "        evaluate_pretrained_model(model, dataloader, device, batch_size=batch_size, type_set=\"train\")\n",
        "        model.train()\n",
        "        print(f\"Epoch {epoch + 1} with mean loss: {loss_sum / len(dataloader)}\")\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_pretrained_model(model, test_data, device, batch_size, type_set: str = \"val\"):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    for x, y in test_data:\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(x).sigmoid()\n",
        "\n",
        "        predicted = torch.round(outputs)\n",
        "\n",
        "\n",
        "        correct += sum(predicted.squeeze() == y)\n",
        "\n",
        "    accuracy = correct / (len(test_data) * batch_size)\n",
        "    print(f\"Accuracy on {type_set}: \", accuracy.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt8eDZ__X1i7",
        "outputId": "18feb9d5-f9d4-4beb-9dd3-b989522554e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on val:  0.8132911324501038\n",
            "Accuracy on train:  0.8770211338996887\n",
            "Epoch 1 with mean loss: 0.4029626365917832\n",
            "Accuracy on val:  0.8156645894050598\n",
            "Accuracy on train:  0.8990982174873352\n",
            "Epoch 2 with mean loss: 0.33343674983847793\n",
            "Accuracy on val:  0.8291139602661133\n",
            "Accuracy on train:  0.8936566710472107\n",
            "Epoch 3 with mean loss: 0.3062849574865986\n",
            "Accuracy on val:  0.8291139602661133\n",
            "Accuracy on train:  0.9357897639274597\n",
            "Epoch 4 with mean loss: 0.27203851192262934\n",
            "Accuracy on val:  0.8346519470214844\n",
            "Accuracy on train:  0.9404539465904236\n",
            "Epoch 5 with mean loss: 0.24828576045435163\n",
            "Accuracy on val:  0.8101266026496887\n",
            "Accuracy on train:  0.829135537147522\n",
            "Epoch 1 with mean loss: 0.4516307460653841\n",
            "Accuracy on val:  0.8283228278160095\n",
            "Accuracy on train:  0.8700248599052429\n",
            "Epoch 2 with mean loss: 0.3729506469614322\n",
            "Accuracy on val:  0.8409810066223145\n",
            "Accuracy on train:  0.8813743591308594\n",
            "Epoch 3 with mean loss: 0.3575314890908365\n",
            "Accuracy on val:  0.814873456954956\n",
            "Accuracy on train:  0.8767101764678955\n",
            "Epoch 4 with mean loss: 0.34770561641647446\n",
            "Accuracy on val:  0.8488924503326416\n",
            "Accuracy on train:  0.898942768573761\n",
            "Epoch 5 with mean loss: 0.3277264844477918\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.load(\"vggmodel.pkl\"), torch.load(\"vggmodel_labels.pkl\"))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.load(\"vggmodel_test.pkl\"), torch.load(\"vggmodel_labels_test.pkl\"))\n",
        "train = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "train_pretrained_model(vgg_classifier, train, test, device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.load(\"resnet.pkl\"), torch.load(\"resnet_labels.pkl\"))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.load(\"resnet_test.pkl\"), torch.load(\"resnet_labels_test.pkl\"))\n",
        "train = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "train_pretrained_model(resnet_classifier, train, test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jehNZkgEF50"
      },
      "outputs": [],
      "source": [
        "def compute_and_save_features(model, test_folder_path, transform_function, device):\n",
        "\n",
        "    model.eval()\n",
        "    folder = ImageFolder(test_folder_path, transform=transform_function)\n",
        "    loader = DataLoader(folder, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        current_features = []\n",
        "        current_labels = []\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            features = model(x)\n",
        "            current_features.append(features)\n",
        "            current_labels.append(y)\n",
        "\n",
        "\n",
        "    return current_features, current_labels\n",
        "\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, transform_function = load_resnetmodel(device)\n",
        "# all layers except classification layer\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "blind_test, blind_labels = compute_and_save_features(model, \"/content/data/a5_data/test_blind\", transform_function, device)\n",
        "torch.save(torch.concat(blind_test), \"resnet_blind_test.pkl\")\n",
        "torch.save(torch.concat(blind_labels), \"resnet_blind_test_labels.pkl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t9s_4cSFnHl"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_pretrained_model(model, test_data, device, batch_size, type_set: str = \"val\"):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    all_predictions = []\n",
        "    for x, y in test_data:\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(x).sigmoid()\n",
        "\n",
        "        predicted = torch.round(outputs).cpu()\n",
        "        all_predictions.extend(predicted)\n",
        "    return all_predictions\n",
        "\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.load(\"resnet_blind_test.pkl\"), torch.load(\"resnet_blind_test_labels.pkl\"))\n",
        "\n",
        "test = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "predictions = evaluate_pretrained_model(resnet_classifier, test, device, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU867hh-GhFn"
      },
      "outputs": [],
      "source": [
        "map = {0: \"MEL\", 1: \"NV\"}\n",
        "\n",
        "labeled_predictions = [map[int(pred)] for pred in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS0U7202Gxqt"
      },
      "outputs": [],
      "source": [
        "with open(\"test.txt\", \"w\") as f:\n",
        "    for label in labeled_predictions:\n",
        "        f.write(label + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
